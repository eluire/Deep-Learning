{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><span style =\"color:black;font-weight:bold\">Install PySpark on Linux </span> </h1>\n",
    "<p></p><p></p>Youtube Tutorial available at: https://www.youtube.com/watch?v=uhVYTNEe_-A\n",
    "<p></p><p></p>Updated Blog post located at: https://medium.com/@GalarnykMichael/install-spark-on-ubuntu-pyspark-231c45677de0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"color:black;font-weight:bold;font-size: 18px;\">Download Spark</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Go to the Apache Spark website. \n",
    "<h5 align=\"center\"> http://spark.apache.org/downloads.html </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Download_linux.png\" height=\"340\" width=\"340\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul> \n",
    "    <li> a) Choose a Spark release (I prefer 2.0.0)</li>\n",
    "    <li> b) Choose a package type: (this installation prefers \"Pre-built for Hadoop 2.7 and later\")</li> \n",
    "    <li> c) Choose a download type: (Direct Download) </li>\n",
    "    <li> d) Download Spark: http://d3kbcqa49mib13.cloudfront.net/spark-2.0.0-bin-hadoop2.7.tgz\n",
    "    </li> (you can click on this or go to http://spark.apache.org/downloads.html to choose your own Spark Version. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Make sure you have java installed on your machine. If you don't, I found the link below useful, but feel free to use something else. \n",
    "\n",
    "\n",
    "http://tecadmin.net/install-oracle-java-8-jdk-8-ubuntu-via-ppa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Go to your home directory. (You can use the command in red)\n",
    "\n",
    "<span style =\"color:red;\"> cd ~ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Unzip the folder in your home directory using the following command. \n",
    "\n",
    "<span style =\"color:red;\"> tar -zxvf spark-2.0.0-bin-hadoop2.7.tgz </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Use the following command to see that you have a .bashrc\n",
    "\n",
    "<span style =\"color:red;\"> ls -a </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Next, we will edit our .bashrc so we can open a spark notebook in any directory\n",
    "\n",
    "<span style =\"color:red;\"> nano .bashrc </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bashrc.png\" height=\"340\" width=\"340\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Don't remove anything in your .bashrc file. Add the following to the bottom of your .bashrc file <br>\n",
    "\n",
    "function snotebook () <br>\n",
    "{\n",
    "\t#Spark path (based on your computer)\n",
    "\tSPARK_PATH=~/spark-2.0.0-bin-hadoop2.7\n",
    "\n",
    "\texport PYSPARK_DRIVER_PYTHON=\"jupyter\"\n",
    "\texport PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\n",
    "\n",
    "\t$SPARK_PATH/bin/pyspark --master local[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Save and exit out of your .bashrc file. \n",
    "Either close the terminal and open a new one or in your terminal type: \n",
    "\n",
    "<span style =\"color:red;\"> source .bashrc </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Done! To test out PySpark please continue to the next tutorial or continue to step 10\n",
    "\n",
    "<b>Word Count Youtube: </b> <br>\n",
    "https://www.youtube.com/watch?v=jg7Z8ctKpEs <br>\n",
    "<b>Word Count Code:<br> </b>https://github.com/mGalarnyk/Python_Tutorials/blob/master/PySpark_Basics/PySpark_Part1_Word_Count_Removing_Punctuation_Pride_Prejudice.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Optional: </b> Word Count of Pride and Prejudice Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "text_file = sc.textFile('Data/Pride_and_Prejudice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional in case sc is returning an error\n",
    "# Reason why we have the getOrCreate code\n",
    "# http://stackoverflow.com/questions/28999332/how-to-access-sparkcontext-in-pyspark-script\n",
    "\n",
    "# sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punc = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_to_clean_str(x):\n",
    "    converted = x.encode('utf-8')\n",
    "    lowercased_str = converted.lower()\n",
    "    # for more difficult cases use re.split(' A|B')\n",
    "    lowercased_str = lowercased_str.replace('--',' ')\n",
    "    clean_str = lowercased_str.translate(None, punc) #Change 1\n",
    "    return clean_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4331, 'the'),\n",
       " (4138, 'to'),\n",
       " (3611, 'of'),\n",
       " (3578, 'and'),\n",
       " (2225, 'her'),\n",
       " (2069, 'i'),\n",
       " (1947, 'a'),\n",
       " (1866, 'in'),\n",
       " (1846, 'was'),\n",
       " (1710, 'she'),\n",
       " (1579, 'that'),\n",
       " (1535, 'it'),\n",
       " (1429, 'not'),\n",
       " (1357, 'you'),\n",
       " (1336, 'he')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_RDD = text_file.flatMap(lambda x: uni_to_clean_str(x).split())\n",
    "one_RDD = one_RDD.map(lambda x: (x,1)) \n",
    "one_RDD = one_RDD.reduceByKey(lambda x,y: x + y)\n",
    "one_RDD = one_RDD.map(lambda x:(x[1],x[0])) \n",
    "one_RDD.sortByKey(False).take(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"color:black;font-weight:bold;font-size: 18px;\">Notes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PYSPARK_DRIVER_PYTHON parameter and the PYSPARK_DRIVER_PYTHON_OPTS parameter are used to launch the PySpark shell in Jupyter Notebook. The --master parameter is used for setting the master node address. Here we launch Spark locally on 2 cores for local testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"color:black;font-weight:bold;font-size: 18px;\">For Python 3 Users</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Python3.png\" height=\"340\" width=\"340\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to add the line in red before you use alias snotebook='$SPARK_PATH/bin/pyspark --master local[2]' line or you will get the error in the image above. \n",
    "<span style =\"color:red;\"> <br>\n",
    "export PYSPARK_PYTHON=python3\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"color:black;font-weight:bold;font-size: 18px;\">Other useful PySpark tutorials</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.dataquest.io/blog/installing-pyspark/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
